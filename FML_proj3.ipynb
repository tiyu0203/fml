{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FML_proj3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM0eBYZmFUW/gnPiJF4qLiB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiyu0203/fml/blob/master/FML_proj3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vluavKsyl9kD"
      },
      "source": [
        "**Frequentist Machine Learning**\n",
        "\n",
        "**Assignment 3**\n",
        "\n",
        "**Jonathan Lam, Tiffany Yu, Harris Paspuleti**\n",
        "\n",
        "Re-implement the example in section 7.10.2 using any simple, out of the box classifier (like K nearest neighbors from sci-kit). Reproduce the results for the incorrect and correct way of doing cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIqAx1V0lkzu",
        "outputId": "5fa6b8cd-8cf6-4676-fe32-3357b77aeb1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#setting up\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "# Consider a scenario with N = 50 samples in two equal-sized classes, and\n",
        "# p = 5000 quantitative predictors (standard Gaussian) that are independent\n",
        "# of the class labels.\n",
        "\n",
        "# generate 50 random samples of N(0,1) data w/ 5000 features\n",
        "X = np.random.normal(0,1,[50, 5000])\n",
        "# The true (test) error rate of any classifier is 50%\n",
        "Y = np.concatenate([np.zeros(25), np.ones(25)])\n",
        "np.random.shuffle(Y)\n",
        "\n",
        "#INCORRECT\n",
        "CV_correct = []\n",
        "\n",
        "# Screen the predictors: find a subset of “good” predictors that show fairly\n",
        "# strong (univariate) correlation with the class labels\n",
        "# preprocessing.MinMaxScaler needed because non-negative values needed for SelectKBest\n",
        "X_new = preprocessing.MinMaxScaler().fit_transform(X)\n",
        "X_new = SelectKBest(chi2, k=100).fit_transform(X_new, Y)\n",
        "\n",
        "# Using just this subset of predictors, build a multivariate classifier.\n",
        "neigh = KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "# Use cross-validation to estimate the unknown tuning parameters and to estimate\n",
        "# the prediction error of the final model.\n",
        "# source: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html\n",
        "rkf = RepeatedKFold(n_splits=5, n_repeats=50)\n",
        "for train_index, test_index in rkf.split(X_new):\n",
        "    X_train, X_test = X_new[train_index], X_new[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "    neigh.fit(X_train, Y_train)\n",
        "    CV_correct.append(1-neigh.score(X_test, Y_test))\n",
        "\n",
        "print(\"Average CV Error Rate:\", np.around(np.array(CV_correct).mean(), 3))\n",
        "\n",
        "\"\"\"\n",
        "What has happened? The problem is that the predictors have an unfair\n",
        "advantage, as they were chosen in step (1) on the basis of all of the samples.\n",
        "Leaving samples out after the variables have been selected does not cor-\n",
        "rectly mimic the application of the classifier to a completely independent\n",
        "test set, since these predictors “have already seen” the left out samples.\n",
        "\"\"\"\n",
        "\n",
        "# CORRECT\n",
        "CV_correct = []\n",
        "kbest = SelectKBest(chi2, k=100)\n",
        "\n",
        "# divide the samples into K CV folds at random\n",
        "rkf = RepeatedKFold(n_splits=5, n_repeats=50)\n",
        "for train_index, test_index in rkf.split(X):\n",
        "\n",
        "    # split fold into train and test data\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    # find a subset of good predictors with the highest correlation with the class labels\n",
        "    X_train = preprocessing.MinMaxScaler().fit_transform(X_train)\n",
        "    X_train = kbest.fit_transform(X_train, Y_train)\n",
        "    best_features = kbest.get_support()\n",
        "\n",
        "    # run a KNN (K=1) classification\n",
        "    neigh = KNeighborsClassifier(n_neighbors=1)\n",
        "    neigh.fit(X_train, Y_train)\n",
        "\n",
        "    # evaluate the model on the test dataset\n",
        "    CV_correct.append(1 - neigh.score(X_test[:, best_features], Y_test))\n",
        "\n",
        "print(\"Average CV Error Rate:\", np.around(np.array(CV_correct).mean(), 3))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average CV Error Rate: 0.038\n",
            "Average CV Error Rate: 0.547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VymR_G-mEqf"
      },
      "source": [
        "The average CV error rate from the incorrect way using cross-validationis much lower than the average CV error rate using the correct way using cross-validation. The correct way has a higher average error because it has not seen the test samples, so it cannot use them as predictors. \n"
      ]
    }
  ]
}